"""
Inference Tab - Chat Interface

Provides a chat interface for interacting with the model:
- Real-time text generation
- Tokens per second display
- Model selection (base, SFT, RLHF)
- Generation parameters (temperature, top_k, top_p)

Phase 1: Basic chat functionality
Phase 7: Side-by-side comparison (Base vs SFT vs RLHF)
"""

# TODO: Phase 1 Implementation
# - Chat interface with streaming responses
# - Tokens/sec display
# - Model checkpoint selector
# - Generation hyperparameter controls


def create_inference_tab():
    """Create the inference/chat tab component."""
    raise NotImplementedError("Phase 1: Inference tab")
